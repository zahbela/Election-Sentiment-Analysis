# -*- coding: utf-8 -*-
"""SentimentAnalyzer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kdb1zA-xoncJVIG0nC-SVV5inZnWkrm6
"""

import pandas as pd
import nltk
nltk.download('punkt')

import random
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

from google.colab import drive

drive.mount('/content/drive', force_remount=True)
df_dataset = pd.read_csv("/content/drive/My Drive/CSC 482/training.1600000.processed.noemoticon.csv",header=None, encoding='latin-1')
df_dataset

df_dataset.columns = ["Sentiment", "ID", "Time","Query", "User", "TweetText"]
df_dataset

nltk.download('stopwords')

sentiments = {}
counts = {}
neutral_counts = {}

stop_words = set(stopwords.words('english'))

nltk.download('punkt')

print(int(len(df_dataset)/1000))
for r in range(int(len(df_dataset)/100)):
    tweet = random.randint(1, 1600000)

    text = df_dataset.iloc[tweet]["TweetText"].lower()
    text = ''.join([i if ord(i) < 128 else ' ' for i in text])
    text = word_tokenize(text)
    #text = [w for w in text if not w in stop_words]

    for word in range(len(text)):
      if text[word] not in sentiments:
          if df_dataset.iloc[tweet]["Sentiment"] == 4:
            sentiments[text[word]] = 1
          elif df_dataset.iloc[tweet]["Sentiment"] == 0:
            sentiments[text[word]] = -1

      else:
          if df_dataset.iloc[tweet]["Sentiment"] == 4:
              sentiments[text[word]] = sentiments[text[word]] + 1
          elif df_dataset.iloc[tweet]["Sentiment"] == 0:
              sentiments[text[word]] = sentiments[text[word]] - 1

      if text[word] not in neutral_counts and df_dataset.iloc[tweet]["Sentiment"] == 2:
        neutral_counts[text[word]] = 1
      elif df_dataset.iloc[tweet]["Sentiment"] == 2:
        neutral_counts[text[word]] = neutral_counts[text[word]] + 1

      if text[word] not in counts:
        counts[text[word]] = 1
      else:
        counts[text[word]] = counts[text[word]] + 1

print(sentiments)

for key, value in counts.items():
    if value <= 1 and key in sentiments:
        del sentiments[key]
    elif key in neutral_counts and neutral_counts[key] > value:
        del sentiments[key]
    elif key in sentiments:
        sentiments[key] = float(sentiments[key]) / float(value)

i = 0

stop_words.add(".")
stop_words.add(",")
sentiments["vote"] = 1.0


tests = [# Test set: Twitter sampled
         "My vote has been cast. Warren would make an awesome president",
         "To be completely honest, I am All in with @ewarren and still plan to vote for her in primary",
         # Test set: Made-up
         "I hate Biden",
         "Sanders is a cool dude",
         "Trump makes me upset",
         # Pulled set, parsed into sentences
         "To #Sanders supporters feeling sadness tonight: I see you.",
         "Losing #Warren broke my heart. Sit with your feelings (& glass of wine?) and breathe.",
         "The fact that #ElizabethWarren is trending on the night of a debate that she wasn’t even in tells you who actually deserves to be winning. I only hope and pray we convince @ewarren to go through all of this again in 2024, because this country needs her more than ever.",
         "Man I’m over this. I’m voting for whoever’s against Trump in November.",
         "#ElizabethWarren would have mopped the floor with both of these dudes #DemocraticDebate #DemDebate",
         "Did #Bernie just confuse which virus we’re dealing with?! Oh dear looks like a sign of #CognitiveDecline",
         "Democrats hate that #Bernie can’t be bought. Just like all independents like me. Good luck in November",
         "When you called virus based on a country with no proof, you become virus which spread racism #Trump Virus",
         "Imagine you're on a plane going 750 MPH...in a bad storm. There's terrifying turbulence. You fear dying, the flight attendants don't know what's going on and there are no pilots in the cockpit. That's what America is like right now under @realDonaldTrump... #Trump #CoronaVirus"
         ]

df_result = pd.DataFrame(columns=["Text", "President", "Sentiment", "Confidence1", "Confidence2"])
current = 0
for test_text in tests:
    test_text = ''.join([i if ord(i) < 128 else ' ' for i in test_text])
    test_text = word_tokenize(test_text)
    test_text = [w for w in test_text if not w in stop_words]

    total = 0
    count = 0
    count2 = 0
    for i in test_text:
        if i in sentiments:
          if abs(sentiments[i]) > .15:
            total += sentiments[i]
            count += 1
            count2 += counts[i]

    if count > 0:
        print("Text:", tests[current])
        if "warren" in tests[current].lower() or "elizabeth" in tests[current].lower():
          df_result = df_result.append({'Text' : tests[current],'President' : 'Warren', 'Sentiment' : total/count, 'Confidence1' : count, 'Confidence2' : count2} , ignore_index=True)
          print("\tWarren; ", end="")
        if "sanders" in tests[current].lower() or "bernie" in tests[current].lower():
          df_result = df_result.append({'Text' : tests[current],'President' : 'Sanders', 'Sentiment' : total/count, 'Confidence1' : count, 'Confidence2' : count2} , ignore_index=True)
          print("\tBernie; ", end="")
        if "biden" in tests[current].lower() or "joe" in tests[current].lower():
          df_result = df_result.append({'Text' : tests[current],'President' : 'Biden', 'Sentiment' : total/count, 'Confidence1' : count, 'Confidence2' : count2} , ignore_index=True)
          print("\tBiden; ", end="")
        if "trump" in tests[current].lower() or "donald" in tests[current].lower():
          df_result = df_result.append({'Text' : tests[current],'President' : 'Trump', 'Sentiment' : total/count, 'Confidence1' : count, 'Confidence2' : count2} , ignore_index=True)
          print("\tTrump; ", end="")
        print("Score:",total/count, "Confidence1:", count, "Confidence2:", count2)
    current += 1

df_result

print((df_dataset))

# To download .csv
from google.colab import files

df_result.to_csv('df_result.csv')
files.download('df_result.csv')